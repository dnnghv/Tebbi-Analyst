#!/usr/bin/env python3
"""
Thread Analytics Script
T·ª± ƒë·ªông l·∫•y v√† ph√¢n t√≠ch d·ªØ li·ªáu threads t·ª´ API
"""

import requests
import json
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import pandas as pd
from typing import Dict, List, Any, Optional
import argparse
import os


class ThreadAnalytics:
    def __init__(self, base_url: str = "https://agent-prod.rovitravel.com", output_base_dir: str = "reports"):
        self.base_url = base_url
        self.output_base_dir = output_base_dir
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json'
        })
        
        # Create base directory structure
        self._ensure_directory_structure()
    
    def _ensure_directory_structure(self):
        """T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c b√°o c√°o"""
        if not os.path.exists(self.output_base_dir):
            os.makedirs(self.output_base_dir)
    
    def _get_output_paths(self, timestamp: str = None):
        """L·∫•y ƒë∆∞·ªùng d·∫´n output theo c·∫•u tr√∫c ng√†y"""
        if timestamp is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Parse date from timestamp
        date_str = timestamp.split('_')[0]  # Get YYYYMMDD part
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"  # YYYY-MM-DD
        
        # Create paths
        date_dir = os.path.join(self.output_base_dir, formatted_date)
        reports_dir = os.path.join(date_dir, "reports")
        conversations_dir = os.path.join(date_dir, "conversations")
        
        # Ensure directories exist
        for dir_path in [date_dir, reports_dir, conversations_dir]:
            if not os.path.exists(dir_path):
                os.makedirs(dir_path)
        
        return {
            'date_dir': date_dir,
            'reports_dir': reports_dir, 
            'conversations_dir': conversations_dir,
            'timestamp': timestamp
        }
    
    def fetch_threads(self, limit: int = 100, offset: int = 0) -> List[Dict[str, Any]]:
        """L·∫•y danh s√°ch threads t·ª´ API"""
        url = f"{self.base_url}/threads/search"
        
        payload = {
            "metadata": {},
            "values": {},
            "status": "idle",
            "limit": limit,
            "offset": offset,
            "sort_by": "updated_at",
            "sort_order": "desc"
        }
        
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            data = response.json()
            # API tr·∫£ v·ªÅ tr·ª±c ti·∫øp l√† array threads
            return data if isinstance(data, list) else []
        except requests.exceptions.RequestException as e:
            print(f"L·ªói khi g·ªçi API: {e}")
            return []
    
    def fetch_all_threads(self, max_threads: Optional[int] = None) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ threads v·ªõi ph√¢n trang"""
        all_threads = []
        offset = 0
        limit = 100
        
        print("ƒêang l·∫•y d·ªØ li·ªáu threads...")
        
        while True:
            print(f"  L·∫•y t·ª´ {offset} ƒë·∫øn {offset + limit}")
            threads = self.fetch_threads(limit=limit, offset=offset)
            
            if not threads:
                break
                
            all_threads.extend(threads)
            
            if max_threads and len(all_threads) >= max_threads:
                all_threads = all_threads[:max_threads]
                break
                
            offset += limit
            
            # Tr√°nh qu√° t·∫£i server
            import time
            time.sleep(0.1)
        
        print(f"ƒê√£ l·∫•y ƒë∆∞·ª£c {len(all_threads)} threads")
        return all_threads
    
    def get_thread_history(self, thread_id: str) -> List[Dict[str, Any]]:
        """L·∫•y l·ªãch s·ª≠ th·ª±c thi c·ªßa m·ªôt thread"""
        url = f"{self.base_url}/threads/{thread_id}/history"
        
        try:
            response = self.session.get(url)
            response.raise_for_status()
            data = response.json()
            # API tr·∫£ v·ªÅ tr·ª±c ti·∫øp l√† array history items
            return data if isinstance(data, list) else []
        except requests.exceptions.RequestException as e:
            print(f"L·ªói khi l·∫•y history cho thread {thread_id}: {e}")
            return []
    
    def analyze_threads_by_date(self, threads: List[Dict[str, Any]]) -> Dict[str, int]:
        """Ph√¢n t√≠ch s·ªë l∆∞·ª£ng threads theo ng√†y"""
        threads_by_date = defaultdict(int)
        
        for thread in threads:
            updated_at = thread.get('updated_at')
            if updated_at:
                # Parse th·ªùi gian (gi·∫£ ƒë·ªãnh format ISO)
                try:
                    dt = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                    date_str = dt.strftime('%Y-%m-%d')
                    threads_by_date[date_str] += 1
                except (ValueError, AttributeError):
                    print(f"Kh√¥ng th·ªÉ parse th·ªùi gian: {updated_at}")
        
        return dict(sorted(threads_by_date.items()))
    
    def get_user_metadata(self, thread_id: str) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin user metadata t·ª´ history c·ªßa thread"""
        history_data = self.get_thread_history(thread_id)
        
        if not history_data:
            return {}
        
        # L·∫•y metadata t·ª´ history item ƒë·∫ßu ti√™n (th∆∞·ªùng ch·ª©a user info)
        for item in history_data:
            metadata = item.get('metadata', {})
            if metadata.get('username') or metadata.get('email'):
                return {
                    'username': metadata.get('username', ''),
                    'email': metadata.get('email', ''),
                    'name': metadata.get('name', ''),
                    'phoneNumber': metadata.get('phoneNumber', ''),
                    'user_id': metadata.get('user_id', ''),
                    'userId': metadata.get('userId', '')
                }
        
        return {}

    def analyze_users_with_conversations(self, threads: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Ph√¢n t√≠ch d·ªØ li·ªáu user v·ªõi metadata v√† conversation content"""
        user_threads = defaultdict(list)
        user_details = {}
        thread_conversations = {}
        total_users = set()
        
        print("\nüë• ƒêang thu th·∫≠p th√¥ng tin user metadata v√† conversations...")
        
        for i, thread in enumerate(threads):
            # Progress indicator
            if (i + 1) % 10 == 0:
                print(f"  ƒê√£ x·ª≠ l√Ω {i + 1}/{len(threads)} threads...")
            
            metadata = thread.get('metadata', {})
            user_id = metadata.get('user_id')
            thread_id = thread.get('thread_id')
            
            if user_id and thread_id:
                user_threads[user_id].append(thread_id)
                total_users.add(user_id)
                
                # L·∫•y user metadata n·∫øu ch∆∞a c√≥ (tr√°nh l·∫∑p l·∫°i)
                if user_id not in user_details:
                    user_metadata = self.get_user_metadata(thread_id)
                    if user_metadata:
                        user_details[user_id] = user_metadata
                    else:
                        # Fallback v·ªõi th√¥ng tin c∆° b·∫£n
                        user_details[user_id] = {
                            'username': '',
                            'email': '',
                            'name': '',
                            'phoneNumber': '',
                            # 'user_id': user_id,
                            'userId': user_id
                        }
                
                # L·∫•y conversation content
                history_data = self.get_thread_history(thread_id)
                conversation = self.extract_conversation_from_history(history_data)
                
                # T√≥m t·∫Øt conversation
                if conversation:
                    messages_count = len(conversation)
                    user_messages = [msg for msg in conversation if msg.get('role') == 'User']
                    ai_messages = [msg for msg in conversation if msg.get('role') == 'AI']
                    
                    # L·∫•y tin nh·∫Øn ƒë·∫ßu v√† cu·ªëi
                    first_message = conversation[0].get('content', '') + '...' if conversation else ''
                    last_message = conversation[-1].get('content', '') + '...' if conversation else ''
                    
                    thread_conversations[thread_id] = {
                        'total_messages': messages_count,
                        'user_messages': len(user_messages),
                        'ai_messages': len(ai_messages),
                        'first_message': first_message,
                        'last_message': last_message,
                        'created_at': thread.get('created_at', ''),
                        'updated_at': thread.get('updated_at', ''),
                        'user_id': user_id,
                        'conversation': conversation  # L∆∞u full conversation ƒë·ªÉ d√πng cho web
                    }
                else:
                    thread_conversations[thread_id] = {
                        'total_messages': 0,
                        'user_messages': 0,
                        'ai_messages': 0,
                        'first_message': 'No conversation found',
                        'last_message': 'No conversation found',
                        'created_at': thread.get('created_at', ''),
                        'updated_at': thread.get('updated_at', ''),
                        'user_id': user_id,
                        'conversation': []
                    }
        
        user_stats = {
            'total_users': len(total_users),
            'threads_per_user': {},
            'user_thread_count': Counter(),
            'user_details': user_details,
            'thread_conversations': thread_conversations
        }
        
        for user_id, thread_ids in user_threads.items():
            thread_count = len(thread_ids)
            
            # T√≠nh t·ªïng messages cho user n√†y
            total_messages = sum(thread_conversations.get(tid, {}).get('total_messages', 0) for tid in thread_ids)
            total_user_messages = sum(thread_conversations.get(tid, {}).get('user_messages', 0) for tid in thread_ids)
            
            user_stats['threads_per_user'][user_id] = {
                'thread_count': thread_count,
                'thread_ids': thread_ids,
                'user_info': user_details.get(user_id, {}),
                'total_messages': total_messages,
                'total_user_messages': total_user_messages,
                'avg_messages_per_thread': round(total_messages / thread_count, 2) if thread_count > 0 else 0
            }
            user_stats['user_thread_count'][thread_count] += 1
        
        print(f"‚úÖ Thu th·∫≠p xong metadata cho {len(user_details)} users v√† {len(thread_conversations)} conversations")
        
        return user_stats

    def analyze_users(self, threads: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Wrapper ƒë·ªÉ gi·ªØ t∆∞∆°ng th√≠ch v·ªõi code c≈©"""
        return self.analyze_users_with_conversations(threads)
    
    def generate_report(self, threads: List[Dict[str, Any]]) -> Dict[str, Any]:
        """T·∫°o b√°o c√°o t·ªïng h·ª£p"""
        print("\nƒêang ph√¢n t√≠ch d·ªØ li·ªáu...")
        
        # Th·ªëng k√™ t·ªïng quan
        total_threads = len(threads)
        
        # Ph√¢n t√≠ch theo ng√†y
        threads_by_date = self.analyze_threads_by_date(threads)
        
        # Ph√¢n t√≠ch user
        user_stats = self.analyze_users(threads)
        
        # T√≠nh to√°n th·ªëng k√™
        if user_stats['total_users'] > 0:
            avg_threads_per_user = total_threads / user_stats['total_users']
        else:
            avg_threads_per_user = 0
        
        report = {
            'summary': {
                'total_threads': total_threads,
                'total_users': user_stats['total_users'],
                'avg_threads_per_user': round(avg_threads_per_user, 2),
                'analysis_date': datetime.now().isoformat()
            },
            'threads_by_date': threads_by_date,
            'user_stats': user_stats,
            'top_users': self.get_top_users(user_stats['threads_per_user'])
        }
        
        return report
    
    def get_top_users(self, threads_per_user: Dict[str, Dict], top_n: int = 10) -> List[Dict[str, Any]]:
        """L·∫•y top users c√≥ nhi·ªÅu threads nh·∫•t v·ªõi metadata"""
        sorted_users = sorted(
            threads_per_user.items(),
            key=lambda x: x[1]['thread_count'],
            reverse=True
        )
        
        return [
            {
                'user_id': user_id,
                'thread_count': data['thread_count'],
                'thread_ids': data['thread_ids'][:5],  # Ch·ªâ hi·ªÉn th·ªã 5 thread ƒë·∫ßu
                'user_info': data.get('user_info', {})  # Th√™m metadata
            }
            for user_id, data in sorted_users[:top_n]
        ]
    
    def save_report(self, report: Dict[str, Any], filename: str = None):
        """L∆∞u b√°o c√°o ra file trong c·∫•u tr√∫c th∆∞ m·ª•c"""
        paths = self._get_output_paths()
        
        if filename is None:
            filename = f"thread_analytics_report_{paths['timestamp']}.json"
        elif not filename.endswith('.json'):
            filename = f"{filename}_{paths['timestamp']}.json"
        
        filepath = os.path.join(paths['reports_dir'], filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìÑ ƒê√£ l∆∞u b√°o c√°o JSON v√†o: {filepath}")
        return filepath
    
    def save_report_as_text(self, report: Dict[str, Any], filename: str = None):
        """L∆∞u b√°o c√°o d·∫°ng text v·ªõi c·∫•u tr√∫c th∆∞ m·ª•c theo ng√†y"""
        paths = self._get_output_paths()
        
        if filename is None:
            filename = f"thread_analytics_report_{paths['timestamp']}.txt"
        elif not filename.endswith('.txt'):
            filename = f"{filename}_{paths['timestamp']}.txt"
        
        filepath = os.path.join(paths['reports_dir'], filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            summary = report['summary']
        
            f.write("="*60 + "\n")
            f.write("üìä B√ÅO C√ÅO PH√ÇN T√çCH THREADS\n")
            f.write("="*60 + "\n")
            f.write(f"üìÖ Th·ªùi gian ph√¢n t√≠ch: {summary['analysis_date']}\n")
            f.write(f"üí¨ T·ªïng s·ªë threads: {summary['total_threads']:,}\n")
            f.write(f"üë• T·ªïng s·ªë users: {summary['total_users']:,}\n")
            f.write(f"üìà Trung b√¨nh threads/user: {summary['avg_threads_per_user']}\n\n")
        
            # Threads theo ng√†y
            f.write("üìÖ THREADS THEO NG√ÄY (10 ng√†y g·∫ßn nh·∫•t):\n")
            f.write("-" * 40 + "\n")
            threads_by_date = report['threads_by_date']
            recent_dates = list(threads_by_date.items())[-10:]
            for date, count in recent_dates:
                f.write(f"{date}: {count:,} threads\n")
        
            # Top users
            f.write("\nüèÜ TOP 10 USERS C√ì NHI·ªÄU THREADS NH·∫§T (K√àM METADATA & CONVERSATIONS):\n")
            f.write("-" * 80 + "\n")
            for i, user in enumerate(report['top_users'], 1):
                user_info = user.get('user_info', {})
                username = user_info.get('username', 'N/A')
                email = user_info.get('email', 'N/A')
                name = user_info.get('name', 'N/A')
                phone = user_info.get('phoneNumber', 'N/A')
                
                # L·∫•y conversation stats t·ª´ user_stats
                user_id = user['user_id']
                user_stats = report['user_stats']['threads_per_user'].get(user_id, {})
                total_messages = user_stats.get('total_messages', 0)
                total_user_messages = user_stats.get('total_user_messages', 0)
                avg_messages = user_stats.get('avg_messages_per_thread', 0)
                
                f.write(f"{i:2d}. [{user['thread_count']} threads, {total_messages} messages] {username}\n")
                f.write(f"    üìß Email: {email}\n")
                f.write(f"    üë§ Name: {name}\n")
                f.write(f"    üì± Phone: {phone if phone else 'N/A'}\n")
                f.write(f"    üí¨ Messages: {total_user_messages} user, {total_messages-total_user_messages} AI (avg: {avg_messages}/thread)\n")
                f.write(f"    üÜî User ID: {user['user_id'][:8]}...{user['user_id'][-8:]}\n\n")
            
            # Ph√¢n ph·ªëi threads/user
            f.write("üìä PH√ÇN PH·ªêI S·ªê THREADS/USER:\n")
            f.write("-" * 40 + "\n")
            user_thread_count = report['user_stats']['user_thread_count']
            for thread_count, user_count in sorted(user_thread_count.items())[:10]:
                f.write(f"{thread_count} threads: {user_count} users\n")
            
            # Chi ti·∫øt conversations n·∫øu c√≥
            thread_conversations = report['user_stats'].get('thread_conversations', {})
            if thread_conversations:
                f.write(f"\nüí¨ CHI TI·∫æT {len(thread_conversations)} THREADS V·ªöI CONVERSATIONS:\n")
                f.write("-" * 60 + "\n")
                
                # S·∫Øp x·∫øp theo s·ªë messages gi·∫£m d·∫ßn
                sorted_conversations = sorted(
                    thread_conversations.items(),
                    key=lambda x: x[1].get('total_messages', 0),
                    reverse=True
                )
                
                for i, (thread_id, conv_data) in enumerate(sorted_conversations[:20], 1):  # Top 20
                    f.write(f"{i:2d}. Thread: {thread_id}\n")
                    f.write(f"    üí¨ Messages: {conv_data.get('total_messages', 0)} total ")
                    f.write(f"({conv_data.get('user_messages', 0)} user, {conv_data.get('ai_messages', 0)} AI)\n")
                    f.write(f"    üìÖ Created: {conv_data.get('created_at', 'N/A')}\n")
                    f.write(f"    üîÑ Updated: {conv_data.get('updated_at', 'N/A')}\n")
                    
                    first_msg = conv_data.get('first_message', '')
                    if first_msg and first_msg != 'No conversation found':
                        first_preview = first_msg[:100] + "..." if len(first_msg) > 100 else first_msg
                        f.write(f"    üí≠ First: {first_preview}\n")
                    
                    last_msg = conv_data.get('last_message', '')
                    if last_msg and last_msg != 'No conversation found' and last_msg != first_msg:
                        last_preview = last_msg[:100] + "..." if len(last_msg) > 100 else last_msg
                        f.write(f"    üí≠ Last: {last_preview}\n")
                    f.write("\n")
        
        print(f"\nüìÑ ƒê√£ l∆∞u b√°o c√°o d·∫°ng text v√†o: {filepath}")
        return filepath
    
    def export_to_csv(self, report: Dict[str, Any]):
        """Xu·∫•t d·ªØ li·ªáu ra CSV v·ªõi conversation content trong c·∫•u tr√∫c th∆∞ m·ª•c"""
        paths = self._get_output_paths()
        timestamp = paths['timestamp']
        
        # Export threads by date
        df_dates = pd.DataFrame(list(report['threads_by_date'].items()), 
                               columns=['date', 'thread_count'])
        date_file = os.path.join(paths['reports_dir'], f"threads_by_date_{timestamp}.csv")
        df_dates.to_csv(date_file, index=False)
        print(f"üìÖ ƒê√£ xu·∫•t d·ªØ li·ªáu theo ng√†y: {date_file}")
        
        # Export user stats v·ªõi metadata v√† conversation stats
        user_data = []
        for user_id, data in report['user_stats']['threads_per_user'].items():
            user_info = data.get('user_info', {})
            user_data.append({
                'user_id': user_id,
                'username': user_info.get('username', ''),
                'email': user_info.get('email', ''),
                'name': user_info.get('name', ''),
                'phoneNumber': user_info.get('phoneNumber', ''),
                'thread_count': data['thread_count'],
                'total_messages': data.get('total_messages', 0),
                'total_user_messages': data.get('total_user_messages', 0),
                'avg_messages_per_thread': data.get('avg_messages_per_thread', 0)
            })
        
        df_users = pd.DataFrame(user_data)
        user_file = os.path.join(paths['reports_dir'], f"user_stats_comprehensive_{timestamp}.csv")
        df_users.to_csv(user_file, index=False)
        print(f"üë• ƒê√£ xu·∫•t th·ªëng k√™ users t·ªïng h·ª£p: {user_file}")
        
        # Export detailed thread conversations
        thread_conversations = report['user_stats'].get('thread_conversations', {})
        if thread_conversations:
            conversation_data = []
            for thread_id, conv_data in thread_conversations.items():
                conversation_data.append({
                    'thread_id': thread_id,
                    'user_id': conv_data.get('user_id', ''),
                    'total_messages': conv_data.get('total_messages', 0),
                    'user_messages': conv_data.get('user_messages', 0),
                    'ai_messages': conv_data.get('ai_messages', 0),
                    'first_message_preview': conv_data.get('first_message', ''),
                    'last_message_preview': conv_data.get('last_message', ''),
                    'created_at': conv_data.get('created_at', ''),
                    'updated_at': conv_data.get('updated_at', '')
                })
            
            df_conversations = pd.DataFrame(conversation_data)
            conv_file = os.path.join(paths['reports_dir'], f"thread_conversations_{timestamp}.csv")
            df_conversations.to_csv(conv_file, index=False)
            print(f"üí¨ ƒê√£ xu·∫•t chi ti·∫øt conversations: {conv_file}")
        
        return {
            'date_file': date_file,
            'user_file': user_file,
            'conversation_file': conv_file if thread_conversations else None
        }
    
    def extract_conversation_from_history(self, history_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Extract cu·ªôc h·ªôi tho·∫°i t·ª´ history data"""
        conversation = []
        
        if not history_data or not isinstance(history_data, list):
            return conversation
        
        for item in history_data:
            if not isinstance(item, dict):
                continue
                
            values = item.get('values', {})
            created_at = item.get('created_at', '')
            
            if not values:
                continue
            
            # values c√≥ th·ªÉ l√† dict ho·∫∑c list
            if isinstance(values, dict):
                values_to_process = [values]
            elif isinstance(values, list):
                values_to_process = values
            else:
                continue
            
            for value in values_to_process:
                if not isinstance(value, dict):
                    continue
                    
                # T√¨m messages trong values
                messages = []
                
                # Th·ª≠ messages tr·ª±c ti·∫øp
                direct_messages = value.get('messages', [])
                if isinstance(direct_messages, list):
                    messages.extend(direct_messages)
                elif direct_messages:  # Single message
                    messages.append(direct_messages)
                
                # Th·ª≠ t√¨m trong c√°c key kh√°c c√≥ th·ªÉ ch·ª©a messages
                if not messages:
                    for key, val in value.items():
                        key_lower = key.lower()
                        if any(keyword in key_lower for keyword in ['message', 'chat', 'conversation', 'dialog']):
                            if isinstance(val, list):
                                messages.extend(val)
                            elif isinstance(val, dict):
                                messages.append(val)
                
                # Extract messages
                for msg in messages:
                    if not isinstance(msg, dict):
                        continue
                        
                    msg_type = msg.get('type', msg.get('role', 'unknown'))
                    content = msg.get('content', msg.get('text', msg.get('message', '')))
                    
                    # Handle content n·∫øu l√† list ho·∫∑c dict
                    if isinstance(content, list):
                        content = ' '.join(str(item) for item in content if item)
                    elif isinstance(content, dict):
                        content = str(content)
                    
                    # Ch·ªâ l·∫•y messages c√≥ content v√† role h·ª£p l·ªá
                    if content and str(content).strip() and msg_type in ['human', 'ai', 'user', 'assistant']:
                        role = 'User' if msg_type in ['human', 'user'] else 'AI'
                        
                        conversation.append({
                            'timestamp': created_at,
                            'role': role,
                            'content': str(content).strip()
                        })
        
        return conversation
    
    def export_conversations_to_file(self, threads: List[Dict[str, Any]], max_conversations: int = 10):
        """Export conversations ra file JSON ƒë·ªÉ review chi ti·∫øt"""
        paths = self._get_output_paths()
        filename = f"conversations_{paths['timestamp']}.json"
        filepath = os.path.join(paths['conversations_dir'], filename)
        
        print(f"\nüì§ XU·∫§T H·ªòI THO·∫†I RA FILE JSON:")
        print("-" * 40)
        
        all_conversations = []
        
        for i, thread in enumerate(threads[:max_conversations]):
            thread_id = thread['thread_id']
            print(f"  X·ª≠ l√Ω thread {i+1}/{min(max_conversations, len(threads))}: {thread_id}")
            
            history_data = self.get_thread_history(thread_id)
            if history_data:
                conversation = self.extract_conversation_from_history(history_data)
                
                if conversation:
                    thread_conversation = {
                        'thread_id': thread_id,
                        'created_at': thread.get('created_at'),
                        'updated_at': thread.get('updated_at'),
                        'metadata': thread.get('metadata', {}),
                        'conversation': conversation,
                        'message_count': len(conversation)
                    }
                    all_conversations.append(thread_conversation)
        
        # L∆∞u file
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(all_conversations, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ ƒê√£ xu·∫•t {len(all_conversations)} cu·ªôc h·ªôi tho·∫°i v√†o file: {filepath}")
        return filepath

    def export_conversations_by_user_thread(self, threads: List[Dict[str, Any]], max_conversations: int = 10):
        """Export conversations theo c·∫•u tr√∫c user/thread ri√™ng bi·ªát"""
        paths = self._get_output_paths()
        base_conv_dir = paths['conversations_dir']
        
        print(f"\nüì§ XU·∫§T H·ªòI THO·∫†I THEO USER/THREAD:")
        print("-" * 40)
        
        exported_count = 0
        user_summary = {}
        
        for i, thread in enumerate(threads[:max_conversations]):
            thread_id = thread['thread_id']
            metadata = thread.get('metadata', {})
            user_id = metadata.get('user_id', 'unknown_user')
            
            print(f"  X·ª≠ l√Ω thread {i+1}/{min(max_conversations, len(threads))}: {thread_id}")
            
            # T·∫°o th∆∞ m·ª•c user n·∫øu ch∆∞a c√≥
            user_dir = os.path.join(base_conv_dir, f"user_{user_id}")
            if not os.path.exists(user_dir):
                os.makedirs(user_dir)
            
            # L·∫•y user metadata ƒë·ªÉ t·∫°o file info
            user_metadata = self.get_user_metadata(thread_id)
            if user_id not in user_summary:
                user_summary[user_id] = {
                    'threads': [],
                    'total_messages': 0,
                    'user_info': user_metadata
                }
            
            history_data = self.get_thread_history(thread_id)
            if history_data:
                conversation = self.extract_conversation_from_history(history_data)
                
                if conversation:
                    exported_count += 1
                    
                    # File cho thread n√†y
                    thread_filename = f"thread_{thread_id}.txt"
                    thread_filepath = os.path.join(user_dir, thread_filename)
                    
                    with open(thread_filepath, 'w', encoding='utf-8') as f:
                        f.write("="*80 + "\n")
                        f.write(f"üí¨ THREAD CONVERSATION: {thread_id}\n")
                        f.write("="*80 + "\n")
                        f.write(f"üìÖ Created: {thread.get('created_at', 'N/A')}\n")
                        f.write(f"üîÑ Updated: {thread.get('updated_at', 'N/A')}\n")
                        f.write(f"üí¨ Total messages: {len(conversation)}\n")
                        f.write(f"üë§ User ID: {user_id}\n")
                        
                        # User metadata
                        if user_metadata:
                            f.write(f"\nüë§ User Information:\n")
                            f.write(f"   - Username: {user_metadata.get('username', 'N/A')}\n")
                            f.write(f"   - Email: {user_metadata.get('email', 'N/A')}\n")
                            f.write(f"   - Name: {user_metadata.get('name', 'N/A')}\n")
                            f.write(f"   - Phone: {user_metadata.get('phoneNumber', 'N/A')}\n")
                        
                        f.write("\n" + "="*80 + "\n")
                        f.write("CONVERSATION HISTORY:\n")
                        f.write("="*80 + "\n")
                        
                        # Xu·∫•t t·ª´ng tin nh·∫Øn
                        for j, msg in enumerate(conversation, 1):
                            role = msg['role']
                            content = str(msg['content'])
                            timestamp = msg.get('timestamp', '')
                            
                            # Icon v√† t√™n cho role
                            if role == "User":
                                display_name = (user_metadata.get('name', '') or 
                                              user_metadata.get('username', '') or 
                                              user_metadata.get('email', '').split('@')[0] if user_metadata.get('email') else 'USER')
                                icon = f"üë§ {display_name.upper()}"
                            else:
                                icon = "ü§ñ AI"
                            
                            f.write(f"\n[{j:03d}] {icon}")
                            if timestamp:
                                try:
                                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                                    formatted_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                                    f.write(f" - {formatted_time}")
                                except:
                                    f.write(f" - {timestamp}")
                            f.write("\n")
                            
                            # Content v·ªõi line wrapping
                            lines = content.split('\n')
                            for line in lines:
                                if len(line) <= 70:
                                    f.write(f"    {line}\n")
                                else:
                                    words = line.split(' ')
                                    current_line = "    "
                                    for word in words:
                                        if len(current_line + word) <= 70:
                                            current_line += word + " "
                                        else:
                                            f.write(current_line.rstrip() + "\n")
                                            current_line = "    " + word + " "
                                    if current_line.strip():
                                        f.write(current_line.rstrip() + "\n")
                            
                            if j < len(conversation):
                                f.write("    " + "¬∑"*50 + "\n")
                    
                    # C·∫≠p nh·∫≠t summary
                    user_summary[user_id]['threads'].append({
                        'thread_id': thread_id,
                        'message_count': len(conversation),
                        'file_path': thread_filepath,
                        'created_at': thread.get('created_at', ''),
                        'updated_at': thread.get('updated_at', '')
                    })
                    user_summary[user_id]['total_messages'] += len(conversation)
                    
                    print(f"    ‚úÖ Saved: {thread_filepath}")
                else:
                    print(f"    ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y conversation cho thread {thread_id}")
            else:
                print(f"    ‚ùå Kh√¥ng th·ªÉ l·∫•y history cho thread {thread_id}")
        
        # T·∫°o file summary cho m·ªói user
        print(f"\nüìä T·∫°o user summaries...")
        for user_id, summary in user_summary.items():
            user_dir = os.path.join(base_conv_dir, f"user_{user_id}")
            summary_file = os.path.join(user_dir, "user_summary.txt")
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                user_info = summary['user_info']
                f.write("="*60 + "\n")
                f.write(f"üë§ USER SUMMARY: {user_id}\n")
                f.write("="*60 + "\n")
                f.write(f"üìÖ Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"üßµ Total threads: {len(summary['threads'])}\n")
                f.write(f"üí¨ Total messages: {summary['total_messages']}\n")
                
                if summary['threads']:
                    avg_msg = summary['total_messages'] / len(summary['threads'])
                    f.write(f"üìà Avg messages/thread: {avg_msg:.1f}\n")
                
                f.write(f"\nüë§ User Information:\n")
                f.write(f"   - Username: {user_info.get('username', 'N/A')}\n")
                f.write(f"   - Email: {user_info.get('email', 'N/A')}\n")
                f.write(f"   - Name: {user_info.get('name', 'N/A')}\n")
                f.write(f"   - Phone: {user_info.get('phoneNumber', 'N/A')}\n")
                
                f.write(f"\nüßµ THREAD LIST:\n")
                f.write("-" * 40 + "\n")
                for i, thread_info in enumerate(summary['threads'], 1):
                    f.write(f"{i:2d}. {thread_info['thread_id']}\n")
                    f.write(f"    üí¨ Messages: {thread_info['message_count']}\n")
                    f.write(f"    üìÖ Created: {thread_info['created_at']}\n")
                    f.write(f"    üìÑ File: {os.path.basename(thread_info['file_path'])}\n\n")
        
        # T·∫°o master summary
        master_summary = os.path.join(base_conv_dir, "conversations_summary.txt")
        with open(master_summary, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("üìä CONVERSATIONS EXPORT SUMMARY\n")
            f.write("="*80 + "\n")
            f.write(f"üìÖ Export time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"üë• Total users: {len(user_summary)}\n")
            f.write(f"üßµ Total threads exported: {exported_count}\n")
            f.write(f"üí¨ Total messages: {sum(s['total_messages'] for s in user_summary.values())}\n\n")
            
            f.write("üìÅ Directory Structure:\n")
            f.write("-" * 40 + "\n")
            for user_id, summary in user_summary.items():
                user_info = summary['user_info']
                display_name = (user_info.get('username', '') or 
                              user_info.get('name', '') or 
                              (user_id[:8] if user_id else 'unknown'))
                f.write(f"üìÅ user_{user_id}/ ({display_name})\n")
                f.write(f"   üìÑ user_summary.txt\n")
                for thread_info in summary['threads']:
                    filename = os.path.basename(thread_info['file_path'])
                    f.write(f"   üìÑ {filename} ({thread_info['message_count']} messages)\n")
                f.write("\n")
        
        print(f"\n‚úÖ ƒê√£ xu·∫•t {exported_count} conversations cho {len(user_summary)} users")
        print(f"üìÅ Structure: conversations/user_[id]/thread_[id].txt")
        print(f"üìä Master summary: {master_summary}")
        
        return {
            'exported_count': exported_count,
            'users_count': len(user_summary),
            'master_summary': master_summary,
            'user_summaries': {uid: os.path.join(base_conv_dir, f"user_{uid}", "user_summary.txt") 
                             for uid in user_summary.keys()}
        }

    def export_conversations_to_txt(self, threads: List[Dict[str, Any]], max_conversations: int = 10):
        """Export conversations ra file txt format d·ªÖ ƒë·ªçc theo c·∫•u tr√∫c user/thread"""
        return self.export_conversations_by_user_thread(threads, max_conversations)

    def print_summary(self, report: Dict[str, Any]):
        """In t√≥m t·∫Øt b√°o c√°o"""
        summary = report['summary']
        
        print("\n" + "="*60)
        print("üìä B√ÅO C√ÅO PH√ÇN T√çCH THREADS")
        print("="*60)
        print(f"üìÖ Th·ªùi gian ph√¢n t√≠ch: {summary['analysis_date']}")
        print(f"üí¨ T·ªïng s·ªë threads: {summary['total_threads']:,}")
        print(f"üë• T·ªïng s·ªë users: {summary['total_users']:,}")
        print(f"üìà Trung b√¨nh threads/user: {summary['avg_threads_per_user']}")
        
        print("\nüìÖ THREADS THEO NG√ÄY (10 ng√†y g·∫ßn nh·∫•t):")
        print("-" * 40)
        threads_by_date = report['threads_by_date']
        recent_dates = list(threads_by_date.items())[-10:]
        for date, count in recent_dates:
            print(f"{date}: {count:,} threads")
        
        print("\nüèÜ TOP 10 USERS C√ì NHI·ªÄU THREADS NH·∫§T (K√àM METADATA & CONVERSATIONS):")
        print("-" * 80)
        for i, user in enumerate(report['top_users'], 1):
            user_info = user.get('user_info', {})
            username = user_info.get('username', 'N/A')
            email = user_info.get('email', 'N/A')
            name = user_info.get('name', 'N/A')
            phone = user_info.get('phoneNumber', 'N/A')
            
            # L·∫•y conversation stats t·ª´ user_stats
            user_id = user['user_id']
            user_stats = report['user_stats']['threads_per_user'].get(user_id, {})
            total_messages = user_stats.get('total_messages', 0)
            total_user_messages = user_stats.get('total_user_messages', 0)
            avg_messages = user_stats.get('avg_messages_per_thread', 0)
            
            print(f"{i:2d}. [{user['thread_count']} threads, {total_messages} messages] {username}")
            print(f"    üìß Email: {email}")
            print(f"    üë§ Name: {name}")
            print(f"    üì± Phone: {phone if phone else 'N/A'}")
            print(f"    üí¨ Messages: {total_user_messages} user, {total_messages-total_user_messages} AI (avg: {avg_messages}/thread)")
            print(f"    üÜî User ID: {user['user_id'][:8]}...{user['user_id'][-8:]}")
            print()
        
        print("\nüìä PH√ÇN PH·ªêI S·ªê THREADS/USER:")
        print("-" * 40)
        user_thread_count = report['user_stats']['user_thread_count']
        for thread_count, user_count in sorted(user_thread_count.items())[:10]:
            print(f"{thread_count} threads: {user_count} users")

    def get_conversation_sample(self, threads: List[Dict[str, Any]], sample_size: int = 5):
        """L·∫•y m·∫´u h·ªôi tho·∫°i t·ª´ m·ªôt s·ªë threads"""
        print(f"\nüí¨ L·∫§Y M·∫™U H·ªòI THO·∫†I T·ª™ {sample_size} THREADS:")
        print("-" * 60)
        
        sample_threads = threads[:sample_size]
        
        for i, thread in enumerate(sample_threads, 1):
            thread_id = thread['thread_id']
            print(f"\n{i}. Thread ID: {thread_id}")
            print("=" * 50)
            
            history_data = self.get_thread_history(thread_id)
            if history_data:
                conversation = self.extract_conversation_from_history(history_data)
                
                if conversation:
                    print(f"üìù T√¨m th·∫•y {len(conversation)} tin nh·∫Øn trong cu·ªôc h·ªôi tho·∫°i:")
                    print("-" * 40)
                    
                    for j, msg in enumerate(conversation[:10]):  # Hi·ªÉn th·ªã t·ªëi ƒëa 10 tin nh·∫Øn
                        role = msg['role']
                        content = str(msg['content'])
                        timestamp = msg['timestamp']
                        
                        # Format content ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp
                        if len(content) > 200:
                            content = content[:200] + "..."
                        
                        # Icon cho role
                        icon = "üë§" if role == "User" else "ü§ñ"
                        
                        print(f"\n{j+1}. {icon} {role}:")
                        if timestamp:
                            print(f"   ‚è∞ {timestamp}")
                        print(f"   üí≠ {content}")
                        
                        if j < len(conversation) - 1:
                            print("   " + "-" * 30)
                    
                    if len(conversation) > 10:
                        print(f"\n   ... v√† {len(conversation) - 10} tin nh·∫Øn kh√°c")
                else:
                    print("   ‚ùå Kh√¥ng t√¨m th·∫•y h·ªôi tho·∫°i trong history n√†y")
                    print("   üîç ƒêang th·ª≠ ph√¢n t√≠ch c·∫•u tr√∫c d·ªØ li·ªáu...")
                    
                    # Debug: hi·ªÉn th·ªã c·∫•u tr√∫c d·ªØ li·ªáu
                    if history_data:
                        first_item = history_data[0]
                        print(f"   üìä Keys trong history item: {list(first_item.keys())}")
                        
                        values = first_item.get('values', [])
                        if values and len(values) > 0 and isinstance(values[0], dict):
                            print(f"   üìä Keys trong values[0]: {list(values[0].keys())}")
            else:
                print("   ‚ùå Kh√¥ng th·ªÉ l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu history")


def cleanup_output_files(keep_latest: int = 3, base_dir: str = "reports"):
    """D·ªçn d·∫πp c√°c files output c≈© theo c·∫•u tr√∫c th∆∞ m·ª•c m·ªõi"""
    import os
    import glob
    import shutil
    from datetime import datetime, timedelta
    
    print(f"\nüßπ D·ªçn d·∫πp th∆∞ m·ª•c {base_dir}, gi·ªØ l·∫°i {keep_latest} ng√†y g·∫ßn nh·∫•t...")
    
    if not os.path.exists(base_dir):
        print(f"‚ö†Ô∏è Th∆∞ m·ª•c {base_dir} kh√¥ng t·ªìn t·∫°i")
        return
    
    # L·∫•y danh s√°ch c√°c th∆∞ m·ª•c ng√†y
    date_dirs = []
    for item in os.listdir(base_dir):
        item_path = os.path.join(base_dir, item)
        if os.path.isdir(item_path) and len(item) == 10 and item.count('-') == 2:  # YYYY-MM-DD format
            try:
                date_obj = datetime.strptime(item, '%Y-%m-%d')
                date_dirs.append((date_obj, item_path))
            except ValueError:
                continue
    
    # S·∫Øp x·∫øp theo ng√†y (m·ªõi nh·∫•t tr∆∞·ªõc)
    date_dirs.sort(key=lambda x: x[0], reverse=True)
    
    cleaned_count = 0
    if len(date_dirs) > keep_latest:
        dirs_to_remove = date_dirs[keep_latest:]
        
        for date_obj, dir_path in dirs_to_remove:
            try:
                shutil.rmtree(dir_path)
                print(f"  ‚ùå ƒê√£ x√≥a th∆∞ m·ª•c: {os.path.basename(dir_path)}")
                cleaned_count += 1
            except Exception as e:
                print(f"  ‚ö†Ô∏è Kh√¥ng th·ªÉ x√≥a {dir_path}: {e}")
    
    print(f"‚úÖ ƒê√£ d·ªçn d·∫πp {cleaned_count} th∆∞ m·ª•c ng√†y")
    
    # Hi·ªÉn th·ªã c√°c th∆∞ m·ª•c c√≤n l·∫°i
    remaining_dirs = [os.path.basename(d[1]) for d in date_dirs[:keep_latest]]
    if remaining_dirs:
        print(f"üìÅ C√≤n l·∫°i {len(remaining_dirs)} th∆∞ m·ª•c: {', '.join(remaining_dirs)}")

def main():
    parser = argparse.ArgumentParser(description='Thread Analytics Tool')
    parser.add_argument('--max-threads', type=int, help='S·ªë l∆∞·ª£ng threads t·ªëi ƒëa ƒë·ªÉ ph√¢n t√≠ch')
    parser.add_argument('--export-csv', action='store_true', help='Xu·∫•t d·ªØ li·ªáu ra CSV')
    parser.add_argument('--chat-sample', type=int, default=5, help='S·ªë l∆∞·ª£ng threads ƒë·ªÉ l·∫•y m·∫´u h·ªôi tho·∫°i')
    parser.add_argument('--export-conversations-txt', type=int, default=10, help='Xu·∫•t N cu·ªôc h·ªôi tho·∫°i ra file TXT (m·∫∑c ƒë·ªãnh: 10)')
    parser.add_argument('--export-conversations-json', type=int, default=0, help='Xu·∫•t N cu·ªôc h·ªôi tho·∫°i ra file JSON')
    parser.add_argument('--output', help='T√™n file ƒë·ªÉ l∆∞u b√°o c√°o (kh√¥ng c·∫ßn extension)')
    parser.add_argument('--json-report', action='store_true', help='L∆∞u b√°o c√°o d·∫°ng JSON thay v√¨ text')
    
    args = parser.parse_args()
    
    # Kh·ªüi t·∫°o analytics
    analytics = ThreadAnalytics()
    
    # L·∫•y d·ªØ li·ªáu threads
    threads = analytics.fetch_all_threads(max_threads=args.max_threads)
    
    if not threads:
        print("Kh√¥ng c√≥ d·ªØ li·ªáu threads ƒë·ªÉ ph√¢n t√≠ch!")
        return
    
    # T·∫°o b√°o c√°o
    report = analytics.generate_report(threads)
    
    # Hi·ªÉn th·ªã t√≥m t·∫Øt
    analytics.print_summary(report)
    
    # L∆∞u b√°o c√°o - m·∫∑c ƒë·ªãnh l√† text format
    if args.json_report:
        output_file = args.output + '.json' if args.output else None
        report_file = analytics.save_report(report, output_file)
    else:
        output_file = args.output + '.txt' if args.output else None
        report_file = analytics.save_report_as_text(report, output_file)
    
    # Xu·∫•t CSV n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
    if args.export_csv:
        analytics.export_to_csv(report)
    
    # L·∫•y m·∫´u conversation
    if args.chat_sample > 0:
        analytics.get_conversation_sample(threads, args.chat_sample)
    
    # Xu·∫•t conversations v·ªõi structure user/thread
    if args.export_conversations_json or args.export_conversations_txt:
        print(f"\nüì• Xu·∫•t conversations cho {args.export_conversations_json or args.export_conversations_txt} threads ƒë·∫ßu ti√™n...")
        result = analytics.export_conversations_by_user_thread(threads, args.export_conversations_json or args.export_conversations_txt)
        print(f"‚úÖ ƒê√£ xu·∫•t {result['exported_count']} conversations cho {result['users_count']} users")
    
    # D·ªçn d·∫πp files c≈©
    cleanup_output_files(keep_latest=3, base_dir=analytics.output_base_dir)
    
    print(f"\n‚úÖ Ho√†n th√†nh! B√°o c√°o ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {report_file}")


if __name__ == "__main__":
    main() 